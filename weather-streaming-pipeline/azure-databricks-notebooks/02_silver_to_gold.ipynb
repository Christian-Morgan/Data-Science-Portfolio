{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "639aa76b-ca04-4094-9cfc-23eaa772fd63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = spark.read.format(\"delta\").load(\"/mnt/silver/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e975d2b-7bdd-4786-8e0c-776adb288612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, monotonically_increasing_id\n",
    "\n",
    "# Define dimension tables\n",
    "dim_location = df_silver.select(\n",
    "    col(\"longitude\"),\n",
    "    col(\"latitude\"),\n",
    "    col(\"sea_level\"),\n",
    "    col(\"grnd_level\"),\n",
    "    col(\"country\"),\n",
    "    col(\"timezone\"),\n",
    "    col(\"city_id\"),\n",
    "    col(\"city_name\")\n",
    ").dropDuplicates([\"city_id\"]).withColumn(\"location_id\", monotonically_increasing_id())\n",
    "\n",
    "dim_conditions = df_silver.select(\n",
    "    col(\"weather_condition\"),\n",
    "    col(\"weather_description\"),\n",
    "    col(\"weather_icon\")\n",
    ").dropDuplicates([\"weather_condition\", \"weather_description\", \"weather_icon\"]).withColumn(\"conditions_id\", monotonically_increasing_id())\n",
    "\n",
    "dim_time = df_silver.select(\n",
    "    col(\"timestamp\"),\n",
    "    col(\"sunrise_time\"),\n",
    "    col(\"sunset_time\")\n",
    ").dropDuplicates([\"timestamp\"]).withColumn(\"time_id\", monotonically_increasing_id())\n",
    "\n",
    "dim_collection = df_silver.select(\n",
    "    col(\"base\"),\n",
    "    col(\"sys_type\"),\n",
    "    col(\"sys_id\"),\n",
    "    col(\"cod\")\n",
    ").dropDuplicates([\"base\", \"sys_type\", \"sys_id\", \"cod\"]).withColumn(\"collection_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49e07716-fd6f-4fe8-8480-ae1e0c79c4b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date\n",
    "\n",
    "\n",
    "fact_weather = df_silver.alias(\"f\") \\\n",
    "    .join(dim_collection.alias(\"s\"),\n",
    "        (col(\"f.base\") == col(\"s.base\")) & \n",
    "        (col(\"f.sys_type\") == col(\"s.sys_type\")) &\n",
    "        (col(\"f.sys_id\") == col(\"s.sys_id\")) & \n",
    "        (col(\"f.cod\") == col(\"s.cod\")), \"left\") \\\n",
    "    .join(dim_conditions.alias(\"c\"), \n",
    "        (col(\"f.weather_condition\") == col(\"c.weather_condition\")) &\n",
    "        (col(\"f.weather_description\") == col(\"c.weather_description\")) &\n",
    "        (col(\"f.weather_icon\") == col(\"c.weather_icon\")), \"left\") \\\n",
    "    .join(dim_time.alias(\"t\"), col(\"f.timestamp\") == col(\"t.timestamp\"), \"left\") \\\n",
    "    .join(dim_location.alias(\"l\"), col(\"f.city_id\") == col(\"l.city_id\"), \"left\") \\\n",
    "    .select(\n",
    "        col(\"l.location_id\"),\n",
    "        col(\"c.conditions_id\"),\n",
    "        col(\"s.collection_id\"),\n",
    "        col(\"t.time_id\"),\n",
    "        col(\"f.temperature\"),\n",
    "        col(\"f.feels_like\"),\n",
    "        col(\"f.temp_min\"),\n",
    "        col(\"f.temp_max\"),\n",
    "        col(\"f.pressure\"),\n",
    "        col(\"f.humidity\"),\n",
    "        col(\"f.wind_speed\"),\n",
    "        col(\"f.wind_degree\"),\n",
    "        col(\"f.wind_gust\"),\n",
    "        col(\"f.cloudiness\"),\n",
    "        col(\"f.visibility\")\n",
    "    ).withColumn(\"weather_id\", monotonically_increasing_id()).withColumn(\"date\", current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93d69cac-052b-488d-9a0e-27dd3a52141b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Create gold schema\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "\n",
    "def create_or_append_delta_table(df, table_name, path, merge_condition):\n",
    "    if not spark.catalog.tableExists(table_name):\n",
    "        (\n",
    "            df.write\n",
    "            .format(\"delta\")\n",
    "            .option(\"path\", path)\n",
    "            .saveAsTable(table_name)\n",
    "        )\n",
    "    else:\n",
    "        delta_table = DeltaTable.forName(spark, table_name)\n",
    "        (\n",
    "            delta_table.alias(\"t\")\n",
    "            .merge(\n",
    "                df.alias(\"s\"),\n",
    "                merge_condition\n",
    "            )\n",
    "            .whenNotMatchedInsertAll()\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "# dim_location\n",
    "create_or_append_delta_table(\n",
    "    dim_location,\n",
    "    \"gold.dim_location\",\n",
    "    \"/mnt/gold/weather/dim_location\",\n",
    "    \"s.city_id = t.city_id\"\n",
    ")\n",
    "\n",
    "# dim_conditions\n",
    "create_or_append_delta_table(\n",
    "    dim_conditions,\n",
    "    \"gold.dim_conditions\",\n",
    "    \"/mnt/gold/weather/dim_conditions\",\n",
    "    \"s.weather_condition = t.weather_condition AND s.weather_description = t.weather_description AND s.weather_icon = t.weather_icon\"\n",
    ")\n",
    "\n",
    "# dim_time\n",
    "create_or_append_delta_table(\n",
    "    dim_time,\n",
    "    \"gold.dim_time\",\n",
    "    \"/mnt/gold/weather/dim_time\",\n",
    "    \"t.timestamp = s.timestamp\"\n",
    ")\n",
    "\n",
    "# dim_collection\n",
    "create_or_append_delta_table(\n",
    "    dim_collection,\n",
    "    \"gold.dim_collection\",\n",
    "    \"/mnt/gold/weather/dim_collection\",\n",
    "    \"s.base = t.base AND s.sys_type = t.sys_type AND s.sys_id = t.sys_id AND s.cod = t.cod\"\n",
    ")\n",
    "\n",
    "# fact_weather (append only)\n",
    "(\n",
    "    fact_weather.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"path\", \"/mnt/gold/weather/fact_weather\")\n",
    "    .saveAsTable(\"gold.fact_weather\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_to_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}