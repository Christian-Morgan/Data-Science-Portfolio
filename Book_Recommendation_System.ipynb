{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d15dc3-45bc-4045-b9a0-bbb8af3530eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from: https://en.wikipedia.org/wiki/List_of_best-selling_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e989905-2d54-4f86-9872-867854420efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 200)\n",
    "# URL of the page to scrape\n",
    "url = \"https://en.m.wikipedia.org/wiki/List_of_best-selling_books\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    books = []\n",
    "    # Find the tables containing the book data\n",
    "    tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "    if tables:\n",
    "        for table_index, table in enumerate(tables, start=1):\n",
    "            # print(f\"Table {table_index}:\")\n",
    "\n",
    "            # Extract the rows\n",
    "            rows = table.find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                # Extract cells (td and th elements)\n",
    "                cells = row.find_all([\"td\", \"th\"])\n",
    "                cell_data = [cell.get_text(strip=True) for cell in cells]\n",
    "                books.append(cell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0caf6d1-c99d-42e6-a4bd-137d6b452b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5599cc-0b43-4d28-82c6-65acdd95b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=books,columns=['Book', 'Author(s)', 'Original language', 'First published', 'Approximate sales', 'Genre',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9250026-16a8-4eda-a979-024d13b54765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns='')\n",
    "df=df.drop(index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3471b-09d7-46b6-b9d8-666a1efe01d0",
   "metadata": {},
   "source": [
    "#### We're only interested in the List of \"best-selling individual books\" tables since they include the genres of each book which will be used as a feature for our recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f4642c-3f7e-4121-a53f-0c1f3ec88c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5739c9-ede1-4c0b-afe2-c0d70e63c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=df[df['Book']=='Book'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351af215-2890-4c94-94b2-5d89165adf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the integer from the strings in each row\n",
    "df['Approximate sales'] = df['Approximate sales'].str.extract(r'(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680995ec-4855-4170-8e1a-cbbbcc226f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436835f8-f424-4f36-a0fa-b8e6118d98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each entry in the Approximate sales column to int type\n",
    "df['Approximate sales'] = df['Approximate sales']*1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6269602-d6f2-4ab3-a172-4b79d72e413a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71c5c44-58d8-4a73-a259-088706d51737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.index.name='book_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8987df2d-a941-47f7-a332-ba307a322d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author(s)</th>\n",
       "      <th>Original language</th>\n",
       "      <th>First published</th>\n",
       "      <th>Approximate sales</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Tale of Two Cities</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>English</td>\n",
       "      <td>1859</td>\n",
       "      <td>200000000</td>\n",
       "      <td>Historical fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Little Prince(Le Petit Prince)</td>\n",
       "      <td>Antoine de Saint-Exupéry</td>\n",
       "      <td>French</td>\n",
       "      <td>1943</td>\n",
       "      <td>200000000</td>\n",
       "      <td>Fantasy,children's fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Alchemist(O Alquimista)</td>\n",
       "      <td>Paulo Coelho</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>1988</td>\n",
       "      <td>150000000</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>English</td>\n",
       "      <td>1997</td>\n",
       "      <td>120000000</td>\n",
       "      <td>Fantasy,children's fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And Then There Were None</td>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>English</td>\n",
       "      <td>1939</td>\n",
       "      <td>100000000</td>\n",
       "      <td>Mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Book                 Author(s)  \\\n",
       "book_id                                                                       \n",
       "0                            A Tale of Two Cities           Charles Dickens   \n",
       "1              The Little Prince(Le Petit Prince)  Antoine de Saint-Exupéry   \n",
       "2                     The Alchemist(O Alquimista)              Paulo Coelho   \n",
       "3        Harry Potter and the Philosopher's Stone             J. K. Rowling   \n",
       "4                        And Then There Were None           Agatha Christie   \n",
       "\n",
       "        Original language First published  Approximate sales  \\\n",
       "book_id                                                        \n",
       "0                 English            1859          200000000   \n",
       "1                  French            1943          200000000   \n",
       "2              Portuguese            1988          150000000   \n",
       "3                 English            1997          120000000   \n",
       "4                 English            1939          100000000   \n",
       "\n",
       "                              Genre  \n",
       "book_id                              \n",
       "0                Historical fiction  \n",
       "1        Fantasy,children's fiction  \n",
       "2                           Fantasy  \n",
       "3        Fantasy,children's fiction  \n",
       "4                           Mystery  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728a2cdd-95f6-4329-b884-476e7509f553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book                 0\n",
       "Author(s)            0\n",
       "Original language    0\n",
       "First published      0\n",
       "Approximate sales    0\n",
       "Genre                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f968638a-33a6-4da7-b7ce-725df27e2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow and scikit-learn libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses most TensorFlow logs\n",
    "tf.get_logger().setLevel('ERROR')  # Suppresses TensorFlow warnings\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Lambda, TextVectorization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d500b742-1d39-49e6-8cff-4cf736b248e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "vectorizer = TextVectorization(output_mode='int', max_tokens=5000) # Converts text to integer sequences\n",
    "vectorizer.adapt(df['Book'])\n",
    "\n",
    "# Ensure 'Author(s)' column contains only strings\n",
    "df['Author(s)'] = df['Author(s)'].astype(str).fillna(\"Unknown\")\n",
    "\n",
    "# Now apply text vectorization\n",
    "author_vectorizer = TextVectorization(output_mode='int', max_tokens=5000)\n",
    "author_vectorizer.adapt(df['Author(s)'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Genre'] = label_encoder.fit_transform(df['Genre'])\n",
    "df['Original language'] = label_encoder.fit_transform(df['Original language'])\n",
    "\n",
    "df['First published'] = pd.to_numeric(df['First published'], errors='coerce')\n",
    "df.dropna(subset=['First published'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['First published'] = scaler.fit_transform(df[['First published']])\n",
    "df['Approximate sales'] = scaler.fit_transform(df[['Approximate sales']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412d99b3-32e5-4a87-b1dc-4e414b5e919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Inputs\n",
    "book_input = Input(shape=(1,), dtype=tf.string, name=\"Book\")\n",
    "author_input = Input(shape=(1,), dtype=tf.string, name=\"Author\")\n",
    "genre_input = Input(shape=(1,), name=\"Genre\")\n",
    "lang_input = Input(shape=(1,), name=\"Language\")\n",
    "published_input = Input(shape=(1,), name=\"Published\")\n",
    "sales_input = Input(shape=(1,), name=\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36a50ae5-6a44-4904-ba0d-c7b6220c732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Vectorization and Embedding\n",
    "book_vectorized = vectorizer(book_input)\n",
    "author_vectorized = author_vectorizer(author_input)\n",
    "\n",
    "book_embedding = Embedding(input_dim=5000, output_dim=32)(book_vectorized)\n",
    "author_embedding = Embedding(input_dim=5000, output_dim=32)(author_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4544afe8-66b4-4ac7-95e2-d678cfc60211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean embeddings\n",
    "book_mean = Lambda(lambda x: tf.reduce_mean(x, axis=1))(book_embedding)\n",
    "author_mean = Lambda(lambda x: tf.reduce_mean(x, axis=1))(author_embedding)\n",
    "\n",
    "# Genre and Language Embedding\n",
    "genre_embedding = Embedding(input_dim=df['Genre'].nunique(), output_dim=16)(genre_input)\n",
    "lang_embedding = Embedding(input_dim=df['Original language'].nunique(), output_dim=16)(lang_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8ebefb-aacc-4cb7-b5b2-ea7c1e9ae882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze the embeddings to remove the extra dimension\n",
    "genre_squeezed = Lambda(lambda x: tf.squeeze(x, axis=1))(genre_embedding)\n",
    "lang_squeezed = Lambda(lambda x: tf.squeeze(x, axis=1))(lang_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1278c651-bb36-4654-a0d4-7bd2679dc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Features\n",
    "combined_features = Concatenate()([\n",
    "    book_mean,\n",
    "    author_mean,\n",
    "    genre_squeezed,\n",
    "    lang_squeezed,\n",
    "    published_input,\n",
    "    sales_input\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d858c600-ba9f-4e22-82b9-47525bbb9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "vectorizer = TextVectorization(output_mode='int', max_tokens=5000) # Converts text to integer sequences\n",
    "vectorizer.adapt(df['Book'])\n",
    "\n",
    "# Ensure 'Author(s)' column contains only strings\n",
    "df['Author(s)'] = df['Author(s)'].astype(str).fillna(\"Unknown\")\n",
    "\n",
    "# Now apply text vectorization\n",
    "author_vectorizer = TextVectorization(output_mode='int', max_tokens=5000)\n",
    "author_vectorizer.adapt(df['Author(s)'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Genre'] = label_encoder.fit_transform(df['Genre'])\n",
    "df['Original language'] = label_encoder.fit_transform(df['Original language'])\n",
    "\n",
    "df['First published'] = pd.to_numeric(df['First published'], errors='coerce')\n",
    "df.dropna(subset=['First published'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['First published'] = scaler.fit_transform(df[['First published']])\n",
    "df['Approximate sales'] = scaler.fit_transform(df[['Approximate sales']])\n",
    "\n",
    "# Define Model Inputs\n",
    "book_input = Input(shape=(1,), dtype=tf.string, name=\"Book\")\n",
    "author_input = Input(shape=(1,), dtype=tf.string, name=\"Author\")\n",
    "genre_input = Input(shape=(1,), name=\"Genre\")\n",
    "lang_input = Input(shape=(1,), name=\"Language\")\n",
    "published_input = Input(shape=(1,), name=\"Published\")\n",
    "sales_input = Input(shape=(1,), name=\"Sales\")\n",
    "\n",
    "# Text Vectorization and Embedding\n",
    "book_vectorized = vectorizer(book_input)\n",
    "author_vectorized = author_vectorizer(author_input)\n",
    "\n",
    "book_embedding = Embedding(input_dim=5000, output_dim=32)(book_vectorized)\n",
    "author_embedding = Embedding(input_dim=5000, output_dim=32)(author_vectorized)\n",
    "\n",
    "# Compute mean embeddings\n",
    "book_mean = Lambda(lambda x: tf.compat.v1.reduce_mean(x, axis=1))(book_embedding)\n",
    "author_mean = Lambda(lambda x: tf.compat.v1.reduce_mean(x, axis=1))(author_embedding)\n",
    "\n",
    "# Genre and Language Embedding\n",
    "genre_embedding = Embedding(input_dim=df['Genre'].nunique(), output_dim=16)(genre_input)\n",
    "lang_embedding = Embedding(input_dim=df['Original language'].nunique(), output_dim=16)(lang_input)\n",
    "\n",
    "# Squeeze the embeddings to remove the extra dimension\n",
    "genre_squeezed = Lambda(lambda x: tf.squeeze(x, axis=1))(genre_embedding)\n",
    "lang_squeezed = Lambda(lambda x: tf.squeeze(x, axis=1))(lang_embedding)\n",
    "\n",
    "# Combine Features\n",
    "combined_features = Concatenate()([\n",
    "    book_mean,\n",
    "    author_mean,\n",
    "    genre_squeezed,\n",
    "    lang_squeezed,\n",
    "    published_input,\n",
    "    sales_input\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9095e5a6-7877-449a-9e90-7e81e8e1d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Dense Layers\n",
    "dense_layer = Dense(128, activation='relu')(combined_features)\n",
    "output_layer = Dense(64, activation='relu')(dense_layer)\n",
    "\n",
    "# Define Model\n",
    "model = Model(\n",
    "    inputs=[book_input, author_input, genre_input, lang_input, published_input, sales_input],\n",
    "    outputs=output_layer\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare Input Data\n",
    "book_data = df['Book'].astype(str).to_numpy()\n",
    "author_data = df['Author(s)'].astype(str).to_numpy()\n",
    "genre_data = df['Genre'].to_numpy()\n",
    "lang_data = df['Original language'].to_numpy()\n",
    "published_data = df['First published'].to_numpy()\n",
    "sales_data = df['Approximate sales'].to_numpy()\n",
    "\n",
    "# Train the Model\n",
    "book_vectors = model.predict([book_data, author_data, genre_data, lang_data, published_data, sales_data])\n",
    "\n",
    "# Recommendation Function\n",
    "def recommend(book_title, top_n=5):\n",
    "    # Get the index of the book in the dataset\n",
    "    book_idx = df[df['Book'] == book_title].index[0]\n",
    "    \n",
    "    # Convert all inputs to tensors\n",
    "    book_input = tf.convert_to_tensor(df['Book'].values, dtype=tf.string)\n",
    "    author_input = tf.convert_to_tensor(df['Author(s)'].values, dtype=tf.string)\n",
    "    genre_input = tf.convert_to_tensor(df['Genre'].values, dtype=tf.int32)\n",
    "    lang_input = tf.convert_to_tensor(df['Original language'].values, dtype=tf.int32)\n",
    "    published_input = tf.convert_to_tensor(df['First published'].values, dtype=tf.float32)\n",
    "    sales_input = tf.convert_to_tensor(df['Approximate sales'].values, dtype=tf.float32)\n",
    "    \n",
    "    # Use the model to generate book vectors\n",
    "    book_vectors = model.predict([\n",
    "        book_input,\n",
    "        author_input,\n",
    "        genre_input,\n",
    "        lang_input,\n",
    "        published_input,\n",
    "        sales_input\n",
    "    ])\n",
    "    \n",
    "    # Extract the vector for the given book\n",
    "    book_vector = book_vectors[book_idx]\n",
    "    \n",
    "    # Compute similarities between the given book and all others\n",
    "    similarities = np.dot(book_vectors, book_vector) / (\n",
    "        np.linalg.norm(book_vectors, axis=1) * np.linalg.norm(book_vector)\n",
    "    )\n",
    "    \n",
    "    # Get indices of the most similar books (excluding the input book itself)\n",
    "    similar_books = np.argsort(similarities)[::-1][1 : top_n + 1]\n",
    "    \n",
    "    # Return the titles of the recommended books\n",
    "    return df.iloc[similar_books]['Book'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c509a3b9-ee3c-4848-aa18-bc7d5075ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "The Hobbit\n",
      "The Lion, the Witch and the Wardrobe\n",
      "And Then There Were None\n",
      "Alice's Adventures in Wonderland\n",
      "Harry Potter and the Chamber of Secrets\n",
      "She: A History of Adventure\n",
      "The Catcher in the Rye\n",
      "Harry Potter and the Prisoner of Azkaban\n",
      "Harry Potter and the Deathly Hallows\n",
      "Harry Potter and the Half-Blood Prince\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "recommendations = recommend(\"Harry Potter and the Philosopher's Stone\", top_n=10)\n",
    "for book in recommendations:\n",
    "    print(book)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (TensorFlow)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
